{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing needed libraries"
      ],
      "metadata": {
        "id": "7bvHQ_cHyKt0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-Slg23-x8PE"
      },
      "outputs": [],
      "source": [
        "#Tom's Libraries Addition\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "#Tabitha's Libraries Addition\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1**"
      ],
      "metadata": {
        "id": "9NHWNfcsyo0A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtaining the data set"
      ],
      "metadata": {
        "id": "ShJR3RNlglgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv',index_col = 0)"
      ],
      "metadata": {
        "id": "Xp7eSZ2lgm3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processing the Dataset"
      ],
      "metadata": {
        "id": "KCyQmbqly70R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Goal State\n",
        "y = data[\"two_year_recid\"]\n",
        "\n",
        "#Discarding all unused features\n",
        "used_features = ['sex','age','priors_count','race']\n",
        "\n",
        "\n",
        "discarded_features = []\n",
        "for col in data.columns:\n",
        "  if col not in used_features:\n",
        "    discarded_features.append(col)\n",
        "\n",
        "X = data.drop(columns = discarded_features)\n",
        "\n",
        "#Changing the feature 'sex' from a string into an integer with tag male: 0 and female: 1\n",
        "X['sex'] = X['sex'].replace({'Male':0, 'Female':1})\n",
        "\n",
        "#Converting it to Numpy Array\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "\n",
        "#Using a 80:20 split for the training and testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 23)\n",
        "\n",
        "#Getting the number of samples and features\n",
        "X = np.delete(X, 2, axis = 1)\n",
        "num_samples, num_features = X.shape\n",
        "\n",
        "#Getting the race for training and test set. to be used later\n",
        "X_train_race = X_train\n",
        "X_test_race = X_test[:,2]\n",
        "X_train_race_used = X_train[:,2]\n",
        "\n",
        "#Remodify the data to remove race\n",
        "X_train = np.delete(X_train, 2, axis = 1)\n",
        "X_test = np.delete(X_test, 2, axis = 1)\n",
        "\n",
        "#Converting the data to tensor type\n",
        "X_train = torch.from_numpy(X_train.astype('float32'))\n",
        "X_test = torch.from_numpy(X_test.astype('float32'))\n",
        "y_train = torch.from_numpy(y_train.astype('float32'))\n",
        "y_test = torch.from_numpy(y_test.astype('float32'))\n",
        "\n",
        "#Reducing the shape of the goal vector to just a single column\n",
        "y_train = y_train.view(y_train.shape[0],1)\n",
        "y_test = y_test.view(y_test.shape[0],1)"
      ],
      "metadata": {
        "id": "ttvtGFdDy0CZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "Iag4ILs7IAzM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the Logistic Regression Model"
      ],
      "metadata": {
        "id": "wV_K6GivIqWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(torch.nn.Module):\n",
        "  def __init__(self,n_input_features):\n",
        "    super(LogisticRegression,self).__init__()\n",
        "    self.Linear = torch.nn.Linear(n_input_features, 1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return torch.sigmoid(self.Linear(x))"
      ],
      "metadata": {
        "id": "VZA2kwYgIDtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the model"
      ],
      "metadata": {
        "id": "nNfwvpkIkefM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting up for Accuracy % Losses Graphing\n",
        "training_accs = []\n",
        "test_accs = []\n",
        "training_loss = []\n",
        "test_losses = []\n",
        "epochs = []\n",
        "\n",
        "#Calling the object with num_features (3)\n",
        "model = LogisticRegression(num_features)\n",
        "\n",
        "#Defining the loss as log loss or binary cross entropy loss\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "#Defining the optimizer as Stochastic Gradient Descent with a learning rate of 0.01\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "#Training Loop\n",
        "num_epochs = 100000\n",
        "for epoch in tqdm(range(num_epochs),desc = 'Training Epoch'):\n",
        "\n",
        "  #Call the forward pass\n",
        "  y_pred = model(X_train)\n",
        "  loss = criterion(y_pred,y_train)\n",
        "\n",
        "  #Summing up gradient\n",
        "  loss.backward()\n",
        "\n",
        "  #Call updates\n",
        "  optimizer.step()\n",
        "\n",
        "  #Emptying the gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch % 5000) == 0:\n",
        "    with torch.no_grad():\n",
        "      print(f'\\nepoch: {epoch}')\n",
        "      epochs.append(epoch)\n",
        "\n",
        "      #Figuring out Training Losses and Accuracy\n",
        "      training_acc = y_pred.round().eq(y_train).sum()/float(y_train.shape[0])\n",
        "      training_accs.append(training_acc)\n",
        "      training_loss.append(loss.item())\n",
        "      print(f'Training Loss: {loss.item():.4f} | Training Accuracy: {training_acc}')\n",
        "\n",
        "      #Figuring out Test Losses and Accuracy\n",
        "      y_pred_test = model(X_test).round()\n",
        "      test_acc = y_pred_test.eq(y_test).sum()/float(y_test.shape[0])\n",
        "      test_accs.append(test_acc)\n",
        "      test_loss = criterion(y_pred_test,y_test)\n",
        "      test_losses.append(test_loss.item())\n",
        "      print(f'Test Loss: {test_loss.item():.4f} | Test Accuracy: {test_acc}')\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  y_pred = model(X_test).round()\n",
        "  accuracy = y_pred.eq(y_test).sum()/float(y_test.shape[0])\n",
        "  print('\\n')\n",
        "  print(f'Final Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyQWHAIckfic",
        "outputId": "d3009016-8f47-46ca-c0b4-1eb981d5a599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:   0%|          | 109/100000 [00:00<02:55, 568.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 0\n",
            "Training Loss: 33.3100 | Training Accuracy: 0.4529544413089752\n",
            "Test Loss: 55.8559 | Test Accuracy: 0.44144144654273987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:   5%|▌         | 5259/100000 [00:04<01:01, 1529.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 5000\n",
            "Training Loss: 0.6345 | Training Accuracy: 0.6409634351730347\n",
            "Test Loss: 35.5509 | Test Accuracy: 0.644490659236908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:  10%|█         | 10223/100000 [00:07<00:59, 1521.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 10000\n",
            "Training Loss: 0.6313 | Training Accuracy: 0.6449488997459412\n",
            "Test Loss: 35.2737 | Test Accuracy: 0.6472626328468323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:  15%|█▌        | 15151/100000 [00:11<01:14, 1141.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 15000\n",
            "Training Loss: 0.6287 | Training Accuracy: 0.6470282673835754\n",
            "Test Loss: 34.7886 | Test Accuracy: 0.652113676071167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:  20%|██        | 20224/100000 [00:15<00:51, 1547.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 20000\n",
            "Training Loss: 0.6266 | Training Accuracy: 0.6489343047142029\n",
            "Test Loss: 34.3035 | Test Accuracy: 0.6569646596908569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:  25%|██▌       | 25260/100000 [00:18<00:50, 1476.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 25000\n",
            "Training Loss: 0.6248 | Training Accuracy: 0.651360273361206\n",
            "Test Loss: 33.6105 | Test Accuracy: 0.6638946533203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:  30%|███       | 30285/100000 [00:21<00:47, 1466.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 30000\n",
            "Training Loss: 0.6234 | Training Accuracy: 0.6539594531059265\n",
            "Test Loss: 33.3333 | Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:  35%|███▌      | 35228/100000 [00:25<00:46, 1387.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 35000\n",
            "Training Loss: 0.6223 | Training Accuracy: 0.6556922793388367\n",
            "Test Loss: 33.6105 | Test Accuracy: 0.6638946533203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:  40%|████      | 40281/100000 [00:29<00:38, 1532.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 40000\n",
            "Training Loss: 0.6214 | Training Accuracy: 0.6586380004882812\n",
            "Test Loss: 33.1254 | Test Accuracy: 0.6687456965446472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:  45%|████▌     | 45275/100000 [00:32<00:34, 1568.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 45000\n",
            "Training Loss: 0.6206 | Training Accuracy: 0.6610639691352844\n",
            "Test Loss: 32.9868 | Test Accuracy: 0.6701316833496094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:  50%|█████     | 50181/100000 [00:35<00:45, 1105.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 50000\n",
            "Training Loss: 0.6200 | Training Accuracy: 0.6633166074752808\n",
            "Test Loss: 32.7789 | Test Accuracy: 0.672210693359375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:  55%|█████▌    | 55164/100000 [00:39<00:29, 1515.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 55000\n",
            "Training Loss: 0.6195 | Training Accuracy: 0.664702832698822\n",
            "Test Loss: 32.2938 | Test Accuracy: 0.6770616769790649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:  60%|██████    | 60176/100000 [00:43<00:26, 1517.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 60000\n",
            "Training Loss: 0.6190 | Training Accuracy: 0.6660890579223633\n",
            "Test Loss: 32.1552 | Test Accuracy: 0.6784476637840271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:  65%|██████▌   | 65226/100000 [00:46<00:23, 1473.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 65000\n",
            "Training Loss: 0.6187 | Training Accuracy: 0.6662623286247253\n",
            "Test Loss: 31.9473 | Test Accuracy: 0.6805266737937927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:  70%|███████   | 70247/100000 [00:50<00:21, 1361.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 70000\n",
            "Training Loss: 0.6184 | Training Accuracy: 0.671980619430542\n",
            "Test Loss: 31.1157 | Test Accuracy: 0.6888427138328552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:  75%|███████▌  | 75290/100000 [00:53<00:16, 1520.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 75000\n",
            "Training Loss: 0.6182 | Training Accuracy: 0.6718072891235352\n",
            "Test Loss: 31.1157 | Test Accuracy: 0.6888427138328552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:  80%|████████  | 80196/100000 [00:56<00:12, 1541.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 80000\n",
            "Training Loss: 0.6180 | Training Accuracy: 0.671980619430542\n",
            "Test Loss: 31.1157 | Test Accuracy: 0.6888427138328552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:  85%|████████▌ | 85137/100000 [01:00<00:11, 1305.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 85000\n",
            "Training Loss: 0.6178 | Training Accuracy: 0.6742332577705383\n",
            "Test Loss: 31.3236 | Test Accuracy: 0.6867637038230896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:  90%|█████████ | 90198/100000 [01:04<00:06, 1425.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 90000\n",
            "Training Loss: 0.6177 | Training Accuracy: 0.6744065284729004\n",
            "Test Loss: 31.3236 | Test Accuracy: 0.6867637038230896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch:  95%|█████████▌| 95269/100000 [01:07<00:03, 1478.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 95000\n",
            "Training Loss: 0.6176 | Training Accuracy: 0.6744065284729004\n",
            "Test Loss: 31.3929 | Test Accuracy: 0.6860706806182861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch: 100%|██████████| 100000/100000 [01:10<00:00, 1413.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Final Test Accuracy: 0.6861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graphing Accuracy"
      ],
      "metadata": {
        "id": "Pd9N3j48WGDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs,training_accs, label = \"Training Accuracy\")\n",
        "plt.plot(epochs,test_accs, label = \"Testing Accuracy\")\n",
        "plt.title(\"Testing Accuracy & Training Accuracy for each epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend(loc = \"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "UQ94OFxUWHRW",
        "outputId": "3f9e517d-9dfa-4108-9b38-8166ec9675ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graphing Losses"
      ],
      "metadata": {
        "id": "EtUjyfaqY7n2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs, training_loss, label = \"Training Loss\")\n",
        "plt.plot(epochs, test_losses, label = \"Test Loss\")\n",
        "plt.title(\"Testing Loss & Training Loss for each epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend(loc = \"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ZjHCKcHoY9D-",
        "outputId": "d328f19b-5380-4036-b906-e840950c38eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Checking for False Positive Parity**"
      ],
      "metadata": {
        "id": "mWB08x10ZlWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforming the prediction and target vector to numpy form and transposing them"
      ],
      "metadata": {
        "id": "uqbMklecGRgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred.numpy()\n",
        "y_test = y_test.numpy()\n",
        "y_test = y_test.transpose()\n",
        "y_pred = y_pred.transpose()"
      ],
      "metadata": {
        "id": "zkSO3xRzUtFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determining the False Postiive Ratio for Caucasian and African-American dataset"
      ],
      "metadata": {
        "id": "TY_OrkwTGXhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating caucasian FPR\n",
        "white_true_neg = ((y_test == 0) & (y_pred == 0) & (X_test_race == 'Caucasian')).sum()\n",
        "white_false_positive = ((y_test == 0) & (y_pred == 1) & (X_test_race == 'Caucasian')).sum()\n",
        "white_fpr = white_false_positive / (white_true_neg + white_false_positive)\n",
        "print(\"False Positve Ratio for Caucasian demographic is \" + str(white_fpr))\n",
        "\n",
        "black_true_neg = ((y_test == 0) & (y_pred == 0) & (X_test_race == 'African-American')).sum()\n",
        "black_false_positive = ((y_test == 0) & (y_pred == 1) & (X_test_race == 'African-American')).sum()\n",
        "black_fpr = black_false_positive / (black_true_neg + black_false_positive)\n",
        "print(\"False Positive Ratio for African-American is \" + str(black_fpr))\n",
        "\n",
        "print('Difference between African-American fpr and Caucasian fpr is ' + str(abs(black_fpr - white_fpr)))\n",
        "\n",
        "var = np.sqrt((white_fpr * (1 - white_fpr) / ((X_test_race == 'Caucasian').sum())) + ((black_fpr * (1 - black_fpr))/ (X_test_race == 'African-American').sum()))\n",
        "error = np.sqrt(8) * var\n",
        "\n",
        "if abs(black_fpr - white_fpr) > error:\n",
        "  print(\"Model does not satisfy False Positive Parity\")\n",
        "else:\n",
        "  print(\"Model does satisfy False Positive Parity\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALr8ing_ZHPQ",
        "outputId": "86de7c9f-1667-4a7b-b42b-3ebeedd03c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False Positve Ratio for Caucasian demographic is 0.1498371335504886\n",
            "False Positive Ratio for African-American is 0.28610354223433243\n",
            "Difference between African-American fpr and Caucasian fpr is 0.13626640868384382\n",
            "Model does not satisfy False Positive Parity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that this False Positive Parity Check is done using the test set, while the later False Positive Parity Check with a variable threshold is done using the training set instead since the Calibration is done using the training set as well."
      ],
      "metadata": {
        "id": "LOSywVu2uJlv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Checking for Calibration**"
      ],
      "metadata": {
        "id": "_zPIWIDPdXw7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up African American only training set and Caucasian only training set and their respective target"
      ],
      "metadata": {
        "id": "lJGZA_Aieiic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the target for the training set to numpy form and transposing them"
      ],
      "metadata": {
        "id": "iO_csRR8GyfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.numpy()\n",
        "y_train = y_train.transpose()"
      ],
      "metadata": {
        "id": "4DTOSqXOfP-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividing the dataset into caucasian and african american"
      ],
      "metadata": {
        "id": "Jf9mm4BKG5N9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_white = []\n",
        "X_train_black = []\n",
        "y_train_white = []\n",
        "y_train_black = []\n",
        "\n",
        "#Creating training set for African American and Caucasian\n",
        "for n,i in enumerate(X_train_race):\n",
        "  temp = []\n",
        "  temp2 = []\n",
        "  if i[2] == 'Caucasian':\n",
        "    temp.append(i[0])\n",
        "    temp.append(i[1])\n",
        "    temp.append(i[3])\n",
        "    X_train_white.append(temp)\n",
        "    y_train_white.append(y_train[0][n])\n",
        "  if i[2] == 'African-American':\n",
        "    temp2.append(i[0])\n",
        "    temp2.append(i[1])\n",
        "    temp2.append(i[3])\n",
        "    X_train_black.append(temp2)\n",
        "    y_train_black.append(y_train[0][n])\n",
        "\n",
        "#Choosing only 10 percent of each race. This should be random, but it already is since the training set was randomly selected\n",
        "X_train_black = X_train_black[:int(len(X_train_black) * 0.1)]\n",
        "y_train_black = y_train_black[:int(len(y_train_black) * 0.1)]\n",
        "X_train_white = X_train_white[:int(len(X_train_white) * 0.1)]\n",
        "y_train_white = y_train_white[:int(len(y_train_white) * 0.1)]\n",
        "\n",
        "#Converting the training set tobe tensor format\n",
        "X_train_white = np.asarray(X_train_white)\n",
        "X_train_black = np.asarray(X_train_black)\n",
        "y_train_white = np.asarray(y_train_white)\n",
        "y_train_black = np.asarray(y_train_black)\n",
        "X_train_white = torch.from_numpy(X_train_white.astype('float32'))\n",
        "X_train_black = torch.from_numpy(X_train_black.astype('float32'))\n",
        "y_train_white = torch.from_numpy(y_train_white.astype('float32'))\n",
        "y_train_black = torch.from_numpy(y_train_black.astype('float32'))"
      ],
      "metadata": {
        "id": "spJaXMi1dbjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the calibration score"
      ],
      "metadata": {
        "id": "MPVa7hxwa6AP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_white = model(X_train_white)\n",
        "y_pred_black = model(X_train_black)\n",
        "\n",
        "#Calculating confusion matrix\n",
        "with torch.no_grad():\n",
        "  white_matrix = confusion_matrix(y_train_white, torch.round(y_pred_white))\n",
        "  black_matrix = confusion_matrix(y_train_black, torch.round(y_pred_black))\n",
        "\n",
        "#Calculate Calibration Score\n",
        "score_white_1 = white_matrix[1][1] / (white_matrix[1][1] + white_matrix[0][1])\n",
        "score_black_1 = black_matrix[1][1] / (black_matrix[1][1] + black_matrix[0][1])\n",
        "\n",
        "score_white_0 = white_matrix[0][0] / (white_matrix[0][0] + white_matrix[1][0])\n",
        "score_black_0 = black_matrix[0][0] / (black_matrix[0][0] + black_matrix[1][0])\n",
        "\n",
        "#Calculate Variances and Errors\n",
        "var_1 = ((score_white_1 * (1 - score_white_1)) / X_train_white.shape[0]) + ((score_black_1 * (1 - score_black_1)) / X_train_black.shape[0])\n",
        "error_1 = 2 * np.sqrt(2) * np.sqrt(var_1)\n",
        "var_0 = ((score_white_0 * (1 - score_white_0)) / X_train_white.shape[0]) + ((score_black_0 * (1 - score_black_0)) / X_train_black.shape[0])\n",
        "error_0 = 2 * np.sqrt(2) * np.sqrt(var_0)\n",
        "\n",
        "#Determining if the model is calibrated\n",
        "if (abs(score_white_1 - score_black_1) < error_1) and (abs(score_white_0 - score_black_0) < error_0):\n",
        "  print(\"Model is properly Calibrated\")\n",
        "else:\n",
        "  print(\"Model is not properly Calibrated\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaWTD15KaZht",
        "outputId": "79d9fe62-28f3-48b4-b824-66b2102c34c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is properly Calibrated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Adjusting the Threshold Inorder to Compare Calibration and False Positive Parity**"
      ],
      "metadata": {
        "id": "XPln2U-a2o8c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start first by writing the functions needed inorder to calculate False Positive Rate and Calibration"
      ],
      "metadata": {
        "id": "ohYeNFAG59uR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for Calibration\n"
      ],
      "metadata": {
        "id": "L8HifvK17NOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def determine_calibration(white_threshold, black_threshold, y_pred_white, y_pred_black):\n",
        "\n",
        "  white_threshold = round(white_threshold,1)\n",
        "  black_threshold = round(black_threshold,1)\n",
        "\n",
        "  #Determining the prediction outcome with the given threshold\n",
        "  y_pred_black_actual = []\n",
        "  y_pred_white_actual = []\n",
        "  for i in y_pred_white[0]:\n",
        "    if i > white_threshold:\n",
        "      y_pred_white_actual.append(1)\n",
        "    else:\n",
        "      y_pred_white_actual.append(0)\n",
        "  \n",
        "  for i in y_pred_black[0]:\n",
        "    if i > black_threshold:\n",
        "      y_pred_black_actual.append(1)\n",
        "    else:\n",
        "      y_pred_black_actual.append(0)\n",
        "\n",
        "  #Converting the data back to tensor\n",
        "  y_pred_black_actual = np.asarray(y_pred_black_actual)\n",
        "  y_pred_white_actual = np.asarray(y_pred_white_actual)\n",
        "  y_pred_black_actual = torch.from_numpy(y_pred_black_actual.astype('float32'))\n",
        "  y_pred_white_actual = torch.from_numpy(y_pred_white_actual.astype('float32'))\n",
        "\n",
        "  #Calculate the confusion Matrixes\n",
        "  with torch.no_grad():\n",
        "    white_matrix = confusion_matrix(y_train_white, torch.round(y_pred_white_actual - white_threshold + 0.5))\n",
        "    black_matrix = confusion_matrix(y_train_black, torch.round(y_pred_black_actual  - black_threshold + 0.5))\n",
        "\n",
        "  #Calculate Calibration Score\n",
        "  score_white_1 = round(white_matrix[1][1] / (white_matrix[1][1] + white_matrix[0][1]),1)\n",
        "  score_black_1 = round(black_matrix[1][1] / (black_matrix[1][1] + black_matrix[0][1]),1)\n",
        "\n",
        "  score_white_0 = round(white_matrix[0][0] / (white_matrix[0][0] + white_matrix[1][0]),1)\n",
        "  score_black_0 = round(black_matrix[0][0] / (black_matrix[0][0] + black_matrix[1][0]),1)\n",
        "\n",
        "  #Calculate Variances and Errors\n",
        "  var_1 = ((score_white_1 * (1 - score_white_1)) / X_train_white.shape[0]) + ((score_black_1 * (1 - score_black_1)) / X_train_black.shape[0])\n",
        "  error_1 = 2 * np.sqrt(2) * np.sqrt(var_1)\n",
        "  var_0 = ((score_white_0 * (1 - score_white_0)) / X_train_white.shape[0]) + ((score_black_0 * (1 - score_black_0)) / X_train_black.shape[0])\n",
        "  error_0 = 2 * np.sqrt(2) * np.sqrt(var_0)\n",
        "\n",
        "  #Determining if the model is calibrated\n",
        "  if (abs(score_white_1 - score_black_1) < error_1) and (abs(score_white_0 - score_black_0) < error_0):\n",
        "    print(\"Model is properly Calibrated\\n\")\n",
        "    return True\n",
        "  else:\n",
        "    print(\"Model is not properly Calibrated\\n\")\n",
        "    return False"
      ],
      "metadata": {
        "id": "PZZnJeGL8aFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for False Positive Parity"
      ],
      "metadata": {
        "id": "6hkInxRqCDLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fpr_calculation(white_threshold, black_threshold, y_pred):\n",
        "\n",
        "  white_threshold = round(white_threshold,1)\n",
        "  black_threshold = round(black_threshold,1)\n",
        "\n",
        "  y_pred_black = []\n",
        "  y_pred_white = []\n",
        "  for i in y_pred[0]:\n",
        "    if i > white_threshold:\n",
        "      y_pred_white.append(1)\n",
        "    else:\n",
        "      y_pred_white.append(0)\n",
        "  \n",
        "  for i in y_pred[0]:\n",
        "    if i > black_threshold:\n",
        "      y_pred_black.append(1)\n",
        "    else:\n",
        "      y_pred_black.append(0)\n",
        "\n",
        "  y_pred_black = np.asarray(y_pred_black)\n",
        "  y_pred_white = np.asarray(y_pred_white)\n",
        "\n",
        "  white_true_neg = ((y_train == 0) & (y_pred_white == 0) & (X_train_race_used == 'Caucasian')).sum()\n",
        "  white_false_positive = ((y_train == 0) & (y_pred_white == 1) & (X_train_race_used == 'Caucasian')).sum()\n",
        "  white_fpr = white_false_positive / (white_true_neg + white_false_positive)\n",
        "  #print(\"False Positve Ratio for Caucasian demographic is \" + str(white_fpr))\n",
        "\n",
        "  black_true_neg = ((y_train == 0) & (y_pred_black == 0) & (X_train_race_used == 'African-American')).sum()\n",
        "  black_false_positive = ((y_train == 0) & (y_pred_black == 1) & (X_train_race_used == 'African-American')).sum()\n",
        "  black_fpr = black_false_positive / (black_true_neg + black_false_positive)\n",
        "  #print(\"False Positive Ratio for African-American is \" + str(black_fpr))\n",
        "\n",
        "  var = np.sqrt((white_fpr * (1 - white_fpr) / ((X_train_race_used == 'Caucasian').sum())) + ((black_fpr * (1 - black_fpr))/ (X_train_race_used == 'African-American').sum()))\n",
        "\n",
        "  error = np.sqrt(8) * var\n",
        "\n",
        "  if abs(black_fpr - white_fpr) > error:\n",
        "    print(\"Model does not satisfy False Positive Parity\")\n",
        "    return False\n",
        "  else:\n",
        "    print(\"Model does satisfy False Positive Parity\")\n",
        "    return True"
      ],
      "metadata": {
        "id": "jKZKUPViCK_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looping through different thresholds for both African-American and Caucasian demographic starting at 0.1 ending at 1 for both"
      ],
      "metadata": {
        "id": "yriPZlh10zVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_white = model(X_train_white)\n",
        "y_pred_white = y_pred_white.detach().numpy()\n",
        "y_pred_white = y_pred_white.transpose()\n",
        "\n",
        "y_pred_black = model(X_train_black)\n",
        "y_pred_black = y_pred_black.detach().numpy()\n",
        "y_pred_black = y_pred_black.transpose()\n",
        "\n",
        "y_pred = model(X_train)\n",
        "y_pred = y_pred.detach().numpy()\n",
        "y_pred = y_pred.transpose()\n",
        "\n",
        "ans = []\n",
        "\n",
        "bt = 0.1\n",
        "wt = 0.1\n",
        "while bt < 1:\n",
        "  wt = 0.1\n",
        "  while wt < 1:\n",
        "    print(\"With African-American Threshold \" + str(round(bt,1)) + \" and Caucasian Threshold \" + str(round(wt,1)))\n",
        "    parity = fpr_calculation(wt,bt,y_pred)\n",
        "    cali = determine_calibration(wt, bt, y_pred_white, y_pred_black)\n",
        "\n",
        "    if parity == True and cali == False:\n",
        "      ans.append((round(wt,1),round(bt,1)))\n",
        "    wt += 0.1\n",
        "  bt += 0.1\n",
        "\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDM4wJX2xoEZ",
        "outputId": "3e765177-ac11-413c-f8f4-50332b81fe69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With African-American Threshold 0.1 and Caucasian Threshold 0.1\n",
            "Model does satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.1 and Caucasian Threshold 0.2\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.1 and Caucasian Threshold 0.3\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.1 and Caucasian Threshold 0.4\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.1 and Caucasian Threshold 0.5\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.1 and Caucasian Threshold 0.6\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.1 and Caucasian Threshold 0.7\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.1 and Caucasian Threshold 0.8\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.1 and Caucasian Threshold 0.9\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.1 and Caucasian Threshold 1.0\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.2 and Caucasian Threshold 0.1\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.2 and Caucasian Threshold 0.2\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.2 and Caucasian Threshold 0.3\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.2 and Caucasian Threshold 0.4\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.2 and Caucasian Threshold 0.5\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.2 and Caucasian Threshold 0.6\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.2 and Caucasian Threshold 0.7\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.2 and Caucasian Threshold 0.8\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.2 and Caucasian Threshold 0.9\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.2 and Caucasian Threshold 1.0\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.3 and Caucasian Threshold 0.1\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.3 and Caucasian Threshold 0.2\n",
            "Model does satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.3 and Caucasian Threshold 0.3\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.3 and Caucasian Threshold 0.4\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.3 and Caucasian Threshold 0.5\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.3 and Caucasian Threshold 0.6\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.3 and Caucasian Threshold 0.7\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.3 and Caucasian Threshold 0.8\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.3 and Caucasian Threshold 0.9\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.3 and Caucasian Threshold 1.0\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.4 and Caucasian Threshold 0.1\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.4 and Caucasian Threshold 0.2\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.4 and Caucasian Threshold 0.3\n",
            "Model does satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.4 and Caucasian Threshold 0.4\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.4 and Caucasian Threshold 0.5\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.4 and Caucasian Threshold 0.6\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.4 and Caucasian Threshold 0.7\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.4 and Caucasian Threshold 0.8\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.4 and Caucasian Threshold 0.9\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.4 and Caucasian Threshold 1.0\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.5 and Caucasian Threshold 0.1\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.5 and Caucasian Threshold 0.2\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.5 and Caucasian Threshold 0.3\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.5 and Caucasian Threshold 0.4\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.5 and Caucasian Threshold 0.5\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.5 and Caucasian Threshold 0.6\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.5 and Caucasian Threshold 0.7\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.5 and Caucasian Threshold 0.8\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.5 and Caucasian Threshold 0.9\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.5 and Caucasian Threshold 1.0\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.6 and Caucasian Threshold 0.1\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.6 and Caucasian Threshold 0.2\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.6 and Caucasian Threshold 0.3\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.6 and Caucasian Threshold 0.4\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.6 and Caucasian Threshold 0.5\n",
            "Model does satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.6 and Caucasian Threshold 0.6\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.6 and Caucasian Threshold 0.7\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.6 and Caucasian Threshold 0.8\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.6 and Caucasian Threshold 0.9\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.6 and Caucasian Threshold 1.0\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.7 and Caucasian Threshold 0.1\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.7 and Caucasian Threshold 0.2\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.7 and Caucasian Threshold 0.3\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.7 and Caucasian Threshold 0.4\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.7 and Caucasian Threshold 0.5\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.7 and Caucasian Threshold 0.6\n",
            "Model does satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.7 and Caucasian Threshold 0.7\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.7 and Caucasian Threshold 0.8\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.7 and Caucasian Threshold 0.9\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.7 and Caucasian Threshold 1.0\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.8 and Caucasian Threshold 0.1\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.8 and Caucasian Threshold 0.2\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.8 and Caucasian Threshold 0.3\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.8 and Caucasian Threshold 0.4\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.8 and Caucasian Threshold 0.5\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.8 and Caucasian Threshold 0.6\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.8 and Caucasian Threshold 0.7\n",
            "Model does satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.8 and Caucasian Threshold 0.8\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.8 and Caucasian Threshold 0.9\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.8 and Caucasian Threshold 1.0\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.9 and Caucasian Threshold 0.1\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.9 and Caucasian Threshold 0.2\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.9 and Caucasian Threshold 0.3\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.9 and Caucasian Threshold 0.4\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.9 and Caucasian Threshold 0.5\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.9 and Caucasian Threshold 0.6\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.9 and Caucasian Threshold 0.7\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.9 and Caucasian Threshold 0.8\n",
            "Model does satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.9 and Caucasian Threshold 0.9\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 0.9 and Caucasian Threshold 1.0\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 1.0 and Caucasian Threshold 0.1\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 1.0 and Caucasian Threshold 0.2\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 1.0 and Caucasian Threshold 0.3\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 1.0 and Caucasian Threshold 0.4\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 1.0 and Caucasian Threshold 0.5\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 1.0 and Caucasian Threshold 0.6\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 1.0 and Caucasian Threshold 0.7\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 1.0 and Caucasian Threshold 0.8\n",
            "Model does not satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 1.0 and Caucasian Threshold 0.9\n",
            "Model does satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "With African-American Threshold 1.0 and Caucasian Threshold 1.0\n",
            "Model does satisfy False Positive Parity\n",
            "Model is not properly Calibrated\n",
            "\n",
            "[(0.1, 0.1), (0.7, 0.8), (0.8, 0.9), (0.9, 1.0), (1.0, 1.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two thresholds that satisfies false positive parity (given as (threshold for caucasian, threshold for african-american)) are (0.1,0.1), (0.7,0.8), (0.8,0.9), (0.9,1.0).\n",
        "\n",
        "Note that (1.0,1.0) will be excluded since this data means every data point will result in the same outcome"
      ],
      "metadata": {
        "id": "uKKiSolfOV1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2** (Option 1)\n",
        "\n",
        "**Obtaining validation set:**"
      ],
      "metadata": {
        "id": "OOlkriQIsjcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = data[\"two_year_recid\"]\n",
        "\n",
        "used_features = ['sex','age','priors_count','race']\n",
        "\n",
        "\n",
        "discarded_features = []\n",
        "for col in data.columns:\n",
        "  if col not in used_features:\n",
        "    discarded_features.append(col)\n",
        "\n",
        "X = data.drop(columns = discarded_features)\n",
        "\n",
        "X['sex'] = X['sex'].replace({'Male':0, 'Female':1})\n",
        "\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "\n",
        "# 80% training, 20% validation and testing\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=15)\n",
        "\n",
        "# temp: 50% validation, 50% testing\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=15)\n",
        "\n",
        "X_train_race = X_train\n",
        "X_val_race = X_val[:, 2]\n",
        "X_test_race = X_test[:, 2]\n",
        "\n",
        "X_train = np.delete(X_train, 2, axis = 1)\n",
        "X_val = np.delete(X_val, 2, axis = 1)\n",
        "X_test = np.delete(X_test, 2, axis = 1)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype('float32'))\n",
        "X_val = torch.from_numpy(X_val.astype('float32'))\n",
        "X_test = torch.from_numpy(X_test.astype('float32'))\n",
        "y_train = torch.from_numpy(y_train.astype('float32'))\n",
        "y_val = torch.from_numpy(y_val.astype('float32'))\n",
        "y_test = torch.from_numpy(y_test.astype('float32'))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_val = y_val.view(y_val.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)"
      ],
      "metadata": {
        "id": "VkAbuM55Q3Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Traning and improving on your initial results:**\n",
        "\n",
        "Strategies from the Deep Learning Tuning Playbook:\n",
        "\n",
        "\n",
        "1.  Choosing the optimizer\n",
        "\n",
        "> *   Chose the Adam optimizer recommended in the playbook and tuned one of it's hyperparameters: the learning rate.\n",
        "> > * For <10 trials, only tuned the learning rate\n",
        "> > > *  Set the other hyperparameters: Beta 1, 2, and epsilon as their default values.\n",
        "\n",
        "\n",
        "2.  Choosing the initial configuration\n",
        "\n",
        "> *  Specified (1) model configuration, (2) optimizer hyperparameters, and (3) the number of training steps \n",
        "> > * Tuned the number of hidden layers, the learning rate of the optimizer, and the number of epochs, accordingly.\n",
        "> > * Followed the guide of \"find(ing) a simple, relatively fast, relatively low-resource-consumption configuration that obtains a \"reasonable\" result.\n",
        "> > > * Started with a constant learning rate = 1e-3 and 50 epochs and tuned accordingly from there\n",
        "> > * Implemented learning rate scheduling. \n",
        "\n",
        "3. Exploration vs exploitation\n",
        "\n",
        "> * I identified the learning rate of the optimizer and the fairness hyperparameter, beta as the hyperparameters the losses are most sensitive to. Thus, focused on tuning them as the playbook suggested. \n",
        "\n",
        "\n",
        "I also implemented early stopping to increase the efficiency of the testing.\n",
        "\n",
        "\n",
        "**Strategies that I did not implement:**\n",
        "\n",
        "1. Choosing the batch size:\n",
        "> * I did not choose a specific batch size and just set it as 1 (i.e. stochastic gradient descent)\n",
        "> > * Given the relatively simple model architecture + small dataset, I believed that stochastic gradient descent was a sufficient choice\n",
        "\n",
        "2. Optimizing the input pipeline:\n",
        "> * Since the dataset was relatively small and no complex preprocessing steps were involved, I concluded that the default PyTorch dataloader was sufficient, thus not necessarily optimizing the input pipeline. \n"
      ],
      "metadata": {
        "id": "vJIe8Iw5RhhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FairAdversarialNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(FairAdversarialNetwork, self).__init__()\n",
        "        self.g = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU() # activation\n",
        "        )\n",
        "        self.f_ = nn.Linear(hidden_size, 1) # f_ = f'\n",
        "        self.phi_ = nn.Linear(hidden_size, 1) # phi_ = φ'\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_ = self.g(x) # x_ = x'\n",
        "        y_hat = self.f_(x_) \n",
        "        s_hat = self.phi_(x_) \n",
        "        return y_hat, s_hat\n",
        "\n",
        "input_size = 3  # num of input features\n",
        "hidden_size = 128 # num of hidden units in single hidden layer of FAD: HYPERPARAMETER\n",
        "model = FairAdversarialNetwork(input_size, hidden_size)\n",
        "\n",
        "# cost functions <-- our choice: Binary Cross Entropy Loss\n",
        "err_y = nn.BCELoss()\n",
        "err_s = nn.BCELoss()\n",
        "\n",
        "# optimizers\n",
        "opt_g = optim.Adam(model.g.parameters(), lr=1e-2) # learning rate: HYPERPARAMETER\n",
        "opt_f_ = optim.Adam(model.f_.parameters(), lr=1e-2)\n",
        "opt_phi_ = optim.Adam(model.phi_.parameters(), lr=1e-2)\n",
        "\n",
        "scheduler_g = ReduceLROnPlateau(opt_g, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "scheduler_f_ = ReduceLROnPlateau(opt_f_, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "scheduler_phi_ = ReduceLROnPlateau(opt_phi_, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "num_epochs = 50 # HYPERPARAMETER\n",
        "beta = 0.5  # fairness HYPERPARAMETER\n",
        "\n",
        "patience = 5 # early stopping patience HYPERPARAMETER\n",
        "best_val_loss = float('inf')\n",
        "bad_epochs = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (x, y, s) in enumerate(zip(X_train, y_train, X_train[:, 0])):\n",
        "        x = x.float()\n",
        "        y = y.float()\n",
        "        s = s.float().unsqueeze(-1)  \n",
        "\n",
        "        y_hat, s_hat = model(x)\n",
        "\n",
        "        # to make them within range 0 to 1\n",
        "        y_hat = torch.sigmoid(y_hat)\n",
        "        s_hat = torch.sigmoid(s_hat)\n",
        "\n",
        "        loss_y = err_y(y_hat, y)\n",
        "        loss_s = err_s(s_hat, s)\n",
        "\n",
        "        opt_g.zero_grad()\n",
        "        opt_f_.zero_grad()\n",
        "\n",
        "        loss_y.backward(retain_graph=True)\n",
        "        opt_g.step()\n",
        "        opt_f_.step()\n",
        "\n",
        "        opt_g.zero_grad()\n",
        "        opt_phi_.zero_grad()\n",
        "\n",
        "        loss_s.backward()\n",
        "        for v in model.g.parameters():\n",
        "            v.grad.data = -beta * v.grad.data \n",
        "\n",
        "        opt_g.step()\n",
        "        opt_phi_.step()\n",
        "        \n",
        "    with torch.no_grad():\n",
        "        y_val_hat, _ = model(X_val)\n",
        "        y_val_hat = torch.sigmoid(y_val_hat)\n",
        "        val_loss = err_y(y_val_hat, y_val)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss(y): {loss_y.item()}, Loss(s): {loss_s.item()},  Validation Loss(y): {val_loss.item()}\") \n",
        "\n",
        "    scheduler_g.step(val_loss)\n",
        "    scheduler_f_.step(val_loss)\n",
        "    scheduler_phi_.step(val_loss)\n",
        "\n",
        "    # early stopping:\n",
        "    if val_loss < best_val_loss:\n",
        "      best_val_loss = val_loss\n",
        "      bad_epochs = 0\n",
        "    else:\n",
        "      bad_epochs += 1\n",
        "      if bad_epochs >= patience:\n",
        "        print(\"Early Stopping\")\n",
        "        break\n",
        "\n",
        "y_test_hat, _ = model(X_test)\n",
        "y_test_hat = torch.sigmoid(y_test_hat)\n",
        "\n",
        "y_test_pred = (y_test_hat > 0.5).float()\n",
        "\n",
        "accuracy = torch.mean((y_test_pred == y_test).float()).item()\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "668f6fc8-25ad-4459-e491-6fbcbc1f3a9a",
        "id": "4iW-zvaKRldk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss(y): 0.5231202244758606, Loss(s): 0.08469840884208679,  Validation Loss(y): 0.6392517685890198\n",
            "Epoch 2/50, Loss(y): 0.4813934564590454, Loss(s): 0.1541779339313507,  Validation Loss(y): 0.6273133754730225\n",
            "Epoch 3/50, Loss(y): 0.5757675170898438, Loss(s): 0.17742709815502167,  Validation Loss(y): 0.6229879856109619\n",
            "Epoch 4/50, Loss(y): 0.5833526253700256, Loss(s): 0.17776566743850708,  Validation Loss(y): 0.6233306527137756\n",
            "Epoch 5/50, Loss(y): 0.5864089131355286, Loss(s): 0.17772379517555237,  Validation Loss(y): 0.623771607875824\n",
            "Epoch 6/50, Loss(y): 0.5947917103767395, Loss(s): 0.1788390576839447,  Validation Loss(y): 0.6247473955154419\n",
            "Epoch 7/50, Loss(y): 0.5867666602134705, Loss(s): 0.1765347719192505,  Validation Loss(y): 0.624011754989624\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-03.\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-03.\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-03.\n",
            "Epoch 8/50, Loss(y): 0.6689655780792236, Loss(s): 0.2161078155040741,  Validation Loss(y): 0.6116056442260742\n",
            "Epoch 9/50, Loss(y): 0.6633812785148621, Loss(s): 0.2138150930404663,  Validation Loss(y): 0.6113540530204773\n",
            "Epoch 10/50, Loss(y): 0.6571964621543884, Loss(s): 0.21244651079177856,  Validation Loss(y): 0.6112383008003235\n",
            "Epoch 11/50, Loss(y): 0.64817214012146, Loss(s): 0.2119152694940567,  Validation Loss(y): 0.6111063361167908\n",
            "Epoch 12/50, Loss(y): 0.640400230884552, Loss(s): 0.21172863245010376,  Validation Loss(y): 0.6109327673912048\n",
            "Epoch 13/50, Loss(y): 0.6390382051467896, Loss(s): 0.21140068769454956,  Validation Loss(y): 0.6108254194259644\n",
            "Epoch 14/50, Loss(y): 0.6391867399215698, Loss(s): 0.2111639529466629,  Validation Loss(y): 0.6107391119003296\n",
            "Epoch 15/50, Loss(y): 0.631160318851471, Loss(s): 0.21155011653900146,  Validation Loss(y): 0.6108304262161255\n",
            "Epoch 16/50, Loss(y): 0.6306792497634888, Loss(s): 0.2115899920463562,  Validation Loss(y): 0.6107633113861084\n",
            "Epoch 17/50, Loss(y): 0.6309818625450134, Loss(s): 0.21158279478549957,  Validation Loss(y): 0.6106836199760437\n",
            "Epoch 18/50, Loss(y): 0.6309744119644165, Loss(s): 0.21158990263938904,  Validation Loss(y): 0.6106245517730713\n",
            "Epoch 19/50, Loss(y): 0.6311818361282349, Loss(s): 0.21159207820892334,  Validation Loss(y): 0.6105647683143616\n",
            "Epoch 20/50, Loss(y): 0.6311516761779785, Loss(s): 0.21160992980003357,  Validation Loss(y): 0.6105186939239502\n",
            "Epoch 21/50, Loss(y): 0.631206214427948, Loss(s): 0.2116279900074005,  Validation Loss(y): 0.6104714870452881\n",
            "Epoch 22/50, Loss(y): 0.6314278244972229, Loss(s): 0.21164534986019135,  Validation Loss(y): 0.6104204058647156\n",
            "Epoch 23/50, Loss(y): 0.6314562559127808, Loss(s): 0.21167296171188354,  Validation Loss(y): 0.6103786826133728\n",
            "Epoch 24/50, Loss(y): 0.6314926743507385, Loss(s): 0.21170279383659363,  Validation Loss(y): 0.6103386282920837\n",
            "Epoch 25/50, Loss(y): 0.6314494609832764, Loss(s): 0.2117386907339096,  Validation Loss(y): 0.610302209854126\n",
            "Epoch 26/50, Loss(y): 0.631678581237793, Loss(s): 0.2117665559053421,  Validation Loss(y): 0.6102558970451355\n",
            "Epoch 27/50, Loss(y): 0.6307573318481445, Loss(s): 0.211843341588974,  Validation Loss(y): 0.6102584004402161\n",
            "Epoch 28/50, Loss(y): 0.6311501264572144, Loss(s): 0.21186277270317078,  Validation Loss(y): 0.6102085709571838\n",
            "Epoch 29/50, Loss(y): 0.6308068633079529, Loss(s): 0.21192432940006256,  Validation Loss(y): 0.6101879477500916\n",
            "Epoch 30/50, Loss(y): 0.6307461261749268, Loss(s): 0.21196551620960236,  Validation Loss(y): 0.61015385389328\n",
            "Epoch 31/50, Loss(y): 0.6304017305374146, Loss(s): 0.21201105415821075,  Validation Loss(y): 0.6101319193840027\n",
            "Epoch 32/50, Loss(y): 0.630640983581543, Loss(s): 0.21204158663749695,  Validation Loss(y): 0.6100879311561584\n",
            "Epoch 33/50, Loss(y): 0.6305868029594421, Loss(s): 0.21209032833576202,  Validation Loss(y): 0.6100558042526245\n",
            "Epoch 34/50, Loss(y): 0.6306029558181763, Loss(s): 0.21213796734809875,  Validation Loss(y): 0.6100218296051025\n",
            "Epoch 35/50, Loss(y): 0.6305467486381531, Loss(s): 0.21218730509281158,  Validation Loss(y): 0.6099924445152283\n",
            "Epoch 36/50, Loss(y): 0.6306257247924805, Loss(s): 0.21222813427448273,  Validation Loss(y): 0.6099573969841003\n",
            "Epoch 37/50, Loss(y): 0.6308268904685974, Loss(s): 0.21226124465465546,  Validation Loss(y): 0.6099178791046143\n",
            "Epoch 38/50, Loss(y): 0.6308135390281677, Loss(s): 0.21230250597000122,  Validation Loss(y): 0.6098899245262146\n",
            "Epoch 39/50, Loss(y): 0.6308786273002625, Loss(s): 0.21233919262886047,  Validation Loss(y): 0.6098588705062866\n",
            "Epoch 40/50, Loss(y): 0.6308411955833435, Loss(s): 0.21238011121749878,  Validation Loss(y): 0.6098334193229675\n",
            "Epoch 41/50, Loss(y): 0.6307847499847412, Loss(s): 0.21242164075374603,  Validation Loss(y): 0.6098089218139648\n",
            "Epoch 42/50, Loss(y): 0.6309828162193298, Loss(s): 0.2124556601047516,  Validation Loss(y): 0.6097726821899414\n",
            "Epoch 43/50, Loss(y): 0.6312395334243774, Loss(s): 0.21248678863048553,  Validation Loss(y): 0.6097350120544434\n",
            "Epoch 44/50, Loss(y): 0.6312325596809387, Loss(s): 0.21252436935901642,  Validation Loss(y): 0.6097104549407959\n",
            "Epoch 45/50, Loss(y): 0.6311826705932617, Loss(s): 0.21256405115127563,  Validation Loss(y): 0.6096882820129395\n",
            "Epoch 46/50, Loss(y): 0.6311233639717102, Loss(s): 0.21260380744934082,  Validation Loss(y): 0.609666645526886\n",
            "Epoch 47/50, Loss(y): 0.6310633420944214, Loss(s): 0.21264351904392242,  Validation Loss(y): 0.6096454858779907\n",
            "Epoch 48/50, Loss(y): 0.6311017870903015, Loss(s): 0.21267889440059662,  Validation Loss(y): 0.6096201539039612\n",
            "Epoch 49/50, Loss(y): 0.6313042044639587, Loss(s): 0.2127108871936798,  Validation Loss(y): 0.6095876693725586\n",
            "Epoch 50/50, Loss(y): 0.6312885284423828, Loss(s): 0.21274733543395996,  Validation Loss(y): 0.6095662713050842\n",
            "Accuracy: 68.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mode Collapse:**"
      ],
      "metadata": {
        "id": "E87Dk3Bi7RS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OutcomePredictor(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(OutcomePredictor, self).__init__()\n",
        "        self.fc1 = nn.Linear(hidden_size, 32)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x_):\n",
        "        x = self.fc1(x_)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "# Get the x_ values for the train, validation, and test sets\n",
        "X_train_x_ = model.g(X_train)\n",
        "X_val_x_ = model.g(X_val)\n",
        "X_test_x_ = model.g(X_test)\n",
        "\n",
        "# Create tensors for the x_ values\n",
        "X_train_x_ = torch.from_numpy(X_train_x_.detach().numpy().astype('float32'))\n",
        "X_val_x_ = torch.from_numpy(X_val_x_.detach().numpy().astype('float32'))\n",
        "X_test_x_ = torch.from_numpy(X_test_x_.detach().numpy().astype('float32'))\n",
        "\n",
        "# Train OutcomePredictor using x'(= x_) activations\n",
        "outcome_predictor = OutcomePredictor(hidden_size)\n",
        "outcome_predictor_optimizer = optim.Adam(outcome_predictor.parameters(), lr=0.1)\n",
        "outcome_predictor_loss = nn.BCELoss()\n",
        "\n",
        "scheduler_outcome_predictor = ReduceLROnPlateau(outcome_predictor_optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "num_epochs = 50\n",
        "patience = 5\n",
        "best_val_loss = float('inf')\n",
        "bad_epochs = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for x_, y in zip(X_train_x_, y_train):\n",
        "        x_ = x_.float()\n",
        "        y = y.float()\n",
        "\n",
        "        y_hat = outcome_predictor(x_)\n",
        "\n",
        "        loss = outcome_predictor_loss(y_hat, y)\n",
        "\n",
        "        outcome_predictor_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        outcome_predictor_optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        y_val_hat = outcome_predictor(X_val_x_)\n",
        "        val_loss = outcome_predictor_loss(y_val_hat, y_val)\n",
        "    \n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
        "\n",
        "    scheduler_outcome_predictor.step(val_loss)\n",
        "\n",
        "    # Early stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        bad_epochs = 0\n",
        "    else:\n",
        "        bad_epochs += 1\n",
        "        if bad_epochs >= patience:\n",
        "            print(\"Early Stopping\")\n",
        "            break\n",
        "\n",
        "y_hat_outcome_predictor = (outcome_predictor(X_test_x_) > 0.5).float()\n",
        "\n",
        "accuracy = (y_hat_outcome_predictor == y_test).sum().item() / y_test.shape[0]\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b524167e-fb56-4e78-9e95-419833091230",
        "id": "BVCGPkGORpHG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 0.5872561931610107, Validation Loss: 0.689481258392334\n",
            "Epoch 2/50, Loss: 0.5872560143470764, Validation Loss: 0.689481258392334\n",
            "Epoch 3/50, Loss: 0.5872560143470764, Validation Loss: 0.6894813776016235\n",
            "Epoch 4/50, Loss: 0.5872560143470764, Validation Loss: 0.6894813776016235\n",
            "Epoch 5/50, Loss: 0.5872560143470764, Validation Loss: 0.6894813776016235\n",
            "Epoch 00005: reducing learning rate of group 0 to 1.0000e-02.\n",
            "Epoch 6/50, Loss: 0.6293752193450928, Validation Loss: 0.6893521547317505\n",
            "Epoch 7/50, Loss: 0.6293757557868958, Validation Loss: 0.6893522143363953\n",
            "Epoch 8/50, Loss: 0.6293757557868958, Validation Loss: 0.6893522143363953\n",
            "Epoch 9/50, Loss: 0.6293757557868958, Validation Loss: 0.6893522143363953\n",
            "Epoch 10/50, Loss: 0.6293757557868958, Validation Loss: 0.6893522143363953\n",
            "Epoch 00010: reducing learning rate of group 0 to 1.0000e-03.\n",
            "Epoch 11/50, Loss: 0.6070735454559326, Validation Loss: 0.6890779137611389\n",
            "Epoch 12/50, Loss: 0.6058841943740845, Validation Loss: 0.6890786290168762\n",
            "Epoch 13/50, Loss: 0.6058176159858704, Validation Loss: 0.689078688621521\n",
            "Epoch 14/50, Loss: 0.6058138608932495, Validation Loss: 0.689078688621521\n",
            "Epoch 15/50, Loss: 0.6058136224746704, Validation Loss: 0.689078688621521\n",
            "Epoch 00015: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 16/50, Loss: 0.603087306022644, Validation Loss: 0.689086377620697\n",
            "Early Stopping\n",
            "Accuracy: 53.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random baseline accuracy:"
      ],
      "metadata": {
        "id": "ROiDOGUHJ14T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_predictions = np.random.randint(0, 2, y_test.shape[0])\n",
        "random_accuracy = (random_predictions == y_test.numpy().flatten()).mean()\n",
        "\n",
        "print(f\"Random baseline accuracy: {random_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61NP-WQJJ5oD",
        "outputId": "4615c57d-aa51-41a6-f722-e33a27079ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random baseline accuracy: 54.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see here that the accuracy is about the same as the random baseline accuracy (for this trial, the OutputPredictor accuracy was 53.19% and the random baseline accuracy was 54.16% unlike the main model with an accuracy of 68.01%), thus it is impossible to train a network to predict the outcome of interest from it."
      ],
      "metadata": {
        "id": "ccQ3BtjgVUjx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Improving Performance:**"
      ],
      "metadata": {
        "id": "DG4wtvyt7kaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GradientReversalFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        grad_input = grad_output.neg() * ctx.alpha\n",
        "        return grad_input, None\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "bad_epochs = 0\n",
        "\n",
        "# Training loop with gradient reversal\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (x, y, s) in enumerate(zip(X_train, y_train, X_train[:, 0])):\n",
        "        x = x.float()\n",
        "        y = y.float()\n",
        "        s = s.float().unsqueeze(-1)\n",
        "\n",
        "        y_hat, s_hat = model(x)\n",
        "\n",
        "        y_hat = torch.sigmoid(y_hat)\n",
        "        s_hat = torch.sigmoid(s_hat)\n",
        "\n",
        "        loss_y = err_y(y_hat, y)\n",
        "        loss_s = err_s(s_hat, s)\n",
        "\n",
        "        opt_g.zero_grad()\n",
        "        opt_f_.zero_grad()\n",
        "\n",
        "        loss_y.backward(retain_graph=True)\n",
        "        opt_g.step()\n",
        "        opt_f_.step()\n",
        "\n",
        "        opt_g.zero_grad()\n",
        "        opt_phi_.zero_grad()\n",
        "\n",
        "        # gradient reversal\n",
        "        x_ = model.g(x).detach()\n",
        "        x_.requires_grad_(True)\n",
        "        s_hat = model.phi_(GradientReversalFunction.apply(x_, beta))\n",
        "        s_hat = torch.sigmoid(s_hat)\n",
        "\n",
        "        loss_s = err_s(s_hat, s)\n",
        "        loss_s.backward()\n",
        "        opt_phi_.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        y_val_hat, _ = model(X_val)\n",
        "        y_val_hat = torch.sigmoid(y_val_hat)\n",
        "        val_loss = err_y(y_val_hat, y_val)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss(y): {loss_y.item()}, Loss(s): {loss_s.item()},  Validation Loss(y): {val_loss.item()}\") \n",
        "\n",
        "    scheduler_g.step(val_loss)\n",
        "    scheduler_f_.step(val_loss)\n",
        "    scheduler_phi_.step(val_loss)\n",
        "\n",
        "    # early stopping:\n",
        "    if val_loss < best_val_loss:\n",
        "      best_val_loss = val_loss\n",
        "      bad_epochs = 0\n",
        "    else:\n",
        "      bad_epochs += 1\n",
        "      if bad_epochs >= patience:\n",
        "        print(\"Early Stopping\")\n",
        "        break\n",
        "\n",
        "y_test_hat, _ = model(X_test)\n",
        "y_test_hat = torch.sigmoid(y_test_hat)\n",
        "\n",
        "y_test_pred = (y_test_hat > 0.5).float()\n",
        "\n",
        "accuracy = torch.mean((y_test_pred == y_test).float()).item()\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73cfd539-afef-4f01-b6f7-469106237cf6",
        "id": "05enLSlkRw6q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss(y): 0.6412372589111328, Loss(s): 0.2139877825975418,  Validation Loss(y): 0.6093387603759766\n",
            "Epoch 2/50, Loss(y): 0.6486008167266846, Loss(s): 0.21354207396507263,  Validation Loss(y): 0.6092073917388916\n",
            "Epoch 3/50, Loss(y): 0.6529906988143921, Loss(s): 0.21232746541500092,  Validation Loss(y): 0.6091622114181519\n",
            "Epoch 4/50, Loss(y): 0.6589343547821045, Loss(s): 0.21040812134742737,  Validation Loss(y): 0.6091252565383911\n",
            "Epoch 5/50, Loss(y): 0.6618297100067139, Loss(s): 0.20845931768417358,  Validation Loss(y): 0.6091791987419128\n",
            "Epoch 6/50, Loss(y): 0.6641389727592468, Loss(s): 0.20642583072185516,  Validation Loss(y): 0.6092584133148193\n",
            "Epoch 7/50, Loss(y): 0.6672517657279968, Loss(s): 0.20419777929782867,  Validation Loss(y): 0.6093438267707825\n",
            "Epoch 8/50, Loss(y): 0.6697092652320862, Loss(s): 0.2020144909620285,  Validation Loss(y): 0.6094558238983154\n",
            "Epoch 00058: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 00058: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 00058: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 9/50, Loss(y): 0.6444123983383179, Loss(s): 0.20414334535598755,  Validation Loss(y): 0.6095523238182068\n",
            "Early Stopping\n",
            "Accuracy: 67.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 3**\n",
        "\n",
        "Ethical Reflection"
      ],
      "metadata": {
        "id": "kIBEScsoyoTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. In the context of recidivism prediction for COMPAS, present an argument in favour of aiming for demographic parity.\n",
        "\n",
        "  Demographic Parity can be defined as a concept that aims to ensure that the predicted outcomes or decisions of the model to be fair and unbias. This can be achieved by having the same distribution of positives for every demographic, so that the model can learn to predict the same outcome distribution across different groups. Regardless of factors such as race, and gender. This seems fair in the context of the recidivism prediction for COMPAS. Demographic parity for recidivism prediction for COMPAS would mean having the same proportion of positive classifications for every race demographic, which is fair since it eliminates biases. The biggest concern is that model can replicated human biases in race and gender in selecting recidivism, and therefore having demographic parity would help in eliminating that."
      ],
      "metadata": {
        "id": "2m5k5gvNyrFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. In the context of recidivism prediction for COMPAS, present an argument in favour of aiming for false-positive parity.\n",
        "\n",
        "False-positve parity can be defined as a concept that aims to ensure that the rate of false positive predictions is equal across different demographic groups.In the the context of the recividism prediction for COMPAS, ensuring false-positive parity accross different demographic is fair since it will eliminate racial or gender bias. If false-positive parity is not achieved in this case, there could be racial bias such as more black prisoners are being wrongly classified than white prisoners, or more male are being misclassified than female. As a result, ensuring false positive parity across the demographics will help towards eliminating the racial and gender biases."
      ],
      "metadata": {
        "id": "0dgofBag64Dw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. In the context of recidivism prediction for COMPAS, present an argument in favour of aiming for calibration.\n",
        "\n",
        "Calibration in the context of a machine learning model can be explained as when the machine learning model can output a probability that is accurate to the real world. In another word, the model is an accurate reflection of the events it predicts. In the context of recidivism for COMPAS, there is a strong case for aiming for calibration. The goal of the COMPAS model is to output a probability of reoffending for a person that is accurate based on real world probability of reoffending. For example, if a person has a 65 percent chance of reoffending, the model should be able to predict that. Essentially, a well calibrated model will give an accurate prediction of a prisoner reoffending. This is crucial when looking at different demographics. In a model that is not well calibrated, a group of prisoners with one race demographic that is most likely to offend can be predicted as less likely to offend, which is incorrect, and vice versa.\n"
      ],
      "metadata": {
        "id": "bnB6B1HW_jHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. In the context of recidivism prediction for COMPAS, consider Sharad Goel’s concepts of aggregate social welfare, and aggregate social welfare as computed for each demographic separately. Make one argument in favour of using those concepts. Make two arguments against those thinking that those concepts should guide the design of systems; at least one of those arguments should be specific to the aggregate social welfare as computed for each demograhic separately.\n",
        "\n",
        "\n",
        "In the context of recidivism prediction for COMPAS, one argument can be made in favour of Sharad Goel's concepts of aggregate social welfare and aggregate social welfare as computed for each demographic separetely is that it allows for a more nuanced way of understanding how many different decisions and policies may impact different groups within a certain population. As a result, by calculating social welfare measures for each demographic individually and separately, it becomes easier to spot potential disparities or potential biases in the system, and further work can be done to address these biases.\n",
        "\n",
        "There are two arguments that can also be made against using these concepts to guide the design of systems. The concept of aggregate social welfare oversimplifies the complex nature of social systems. As a result, it may not always be accurate to the interests of all individuals within a population. For example, a policy or decision that maximizes aggregate social welfare may still disproportionaltely harm certain individuals or communities. Secondly, The concept of aggregate social welfare as computed for each demographic separately may lead to the creation of silos that will treat differing groups as isolated from each other. As a result, harmful stereotypes can occur due to the isolation and social division will be encouraged. Furthermore, intersectional identities are not taken into account, where individuals may belong to multiple demographic at the same time, which significantly complicates the analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "M9psA_5AJdCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. There are many contexts in which prediction systems are currently being used. Examples include credit scores; university admissions; insurance rate offers; early-warning systems for deterioriating patients in hospital. Pick one field (not necessarily one of the ones I listed) where you think the ethical considerations are different from the ethical considerations for COMPAS. Argue that the ethical considerations for the two cases are different, and connect your argument to observational and causal measures of fairness that we discussed in class.\n",
        "\n",
        "One field where ethical considerations of predictive algorithms are used to identify patients who are at high risk of developing certain medical conditions or illnesses. In this context, the ethical considerations differ from those for COMPAS. For example, a false negative or false positive prediction can result in much more devasting outcome than the case for COMPAS. A false negative prediction that a patient is not at risk of developing a serious illness could result in a delay of much needed treatment and could lead to a life-threatening condition if delayed for too long. On the flip side, false positive prediction could result in unnecessary medical help, which could be expensive, and could potentially threaten the patient's health. For the case of COMPAS, false negative will remove a prisoner's rights away even though they have earned it but will not threaten anyone's health. As a result, it is important to consider both observational and causal measures of fairness when developing and using predictive algorithms in healthcare. Fairness is one of the key priorities and observational measures of fairness can be used to achieve that; measures include ensuring that the data used to train the algorithm is representative of the entire population, and is well calibrated to not contain biases such as race, or gender. Additionally, causal measures of fairness can be used to ensure that the algorithm is not only accurate but also achieves desirable outcomes, such as reducing healthcare disparities or improving health outcomes for underrepresented groups.\n"
      ],
      "metadata": {
        "id": "mw79fwk3XcAK"
      }
    }
  ]
}
